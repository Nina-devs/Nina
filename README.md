# Nina: The world's first decent C ⇄ JavaScript ⇄ Java transpiler!

What is *Nina*? Nina is my best friend, biggest supporter, and a slightly modified version of JavaScript/Node.JS/TypeScript easily compiled all the way down to compact, performant C code. 

**Nina is ridiculously high peformance and competes with Google's V8 engine. Yes!, you read that right! See the [benchmarks.](#Benchmarks)**

## Getting Started with Nina

Use the Nina CLI program the same as any sane C compiler: `nina input.js -o output.c`

Then, `output.c` is a self-contained C program with `int main() {...}` and everything!, which you can compile and run normally: `cc output.c -o program` and `./program` to run it.

Nina tries to mimic the NodeJS environment and is implementing more of its APIs all the time. See [the NodeJS docs](https://nodejs.org/docs/latest/api/) for more info and examples of how to write your JavaScript programs. For example, here's a hello world program that writes "hello world" to output.txt:

```js
// JavaScript example to write "hello world" to a file
var fs = require("fs");

fs.writeFileSync("./output.txt", "Hello world!");

console.log('"Hello world!" written to output.txt!');
```

Here's the `output.c` generated by Nina:

```c
// Generated C from the JavaScript write "hello world" example
int main() {
    FILE* tmpA_file = fopen("./output.txt", "w");
    size_t tmpB_written = tmpA_file == NULL ? 0 : fwrite("Hello world!", 1, 12, tmpA_file);
    if (tmpB_written != 12) fprintf(stderr, "writeFileSync failed on line 4 of input.js\n"), exit(1);

    printf("\"Hello world!\" written to output.txt!\n");

    return 0;
}
```

<sup>Notice: the includes and others in this example snippet and every example snippet is missing. The full `output.c` has `#include` and some other boilerplate code.</sup>

As you can see, Nina detected that `fs.writeFileSync` is used top-level and omitted its usual error handling faculties, instead abbreviating the error throwing to `fprintf(stderr,...)` to print the error and `exit(1)` to exit the program with an error

Tip: Add the `-fuseful-error-info` flag to generate the neccecary boilerplate code to investigate errors and print out a good description of what is really happening. This is disabled by default (``-fno-useful-error-info`, as `), since it can significantly bloat the size of the generated C code.

* Nina transpiles **itself** from a mix of JavaScript (in the [JS to C transpiler](https://github.com/Nina-devs/nina2c)) and C (in the [C to JS transpiler](https://github.com/c2nina)) to decently-readable C code. Compare [the *readable* generated C code](./libnina.c) to [the source JS](./src/libnina.js) with your own eyes! This proves Nina is ready to take on transpiling whole programs, not just code snippets.
* Unlike the numerous toy JavaScript to C *wanna-be*s out there, *Nina* is very careful about the optimizations/inferences it makes and defaults to generating a sprawling mess of C code covering every edge case in the JavaScript. The full incredible potential of Nina will only be unlocked if you deem your code *safe* for it and help Nina with strong typing guarantees in tricky areas of your code. <br>(Notice [the first line in the *performance-optimized* generated C code](./libnina-fast.c) shows finely-tuned transpile options custom to this project.)
* *Nina* prioritizes performance as high as generated code readability and is free of memory leaks. From intelligent stack-based allocation of short-lived objects via a CoHR/Copy-on-Heap-reference tag (SIGNIFIGANTLY reduces `malloc`/`free`) to ridiculously smart caller-stack type deductions (with thereupon fastpath splitting) to signaling NaN boxed-value compression (reduces memory by ~40%), Nina has it all!

* **Nina can be used as a super-optimizer/minifier to transpile JavaScript to much faster JavaScript!**
<sup>Aack! Please don't take this out of context!, this doesn't work for any random JavaScript because the V8 would have already included that optimization. This only works when you give Nina lots of type information and contractual permission to make various assumptions about how your JavaScript code will run.</sup>
* *Nina* is very similar to JavaScript and most JavaScript is interoperable with *Nina*.
* *Nina* also supports the typing of TypeScript for significantly better codegen and performance!
* *Nina* has a powerful builtin code analyzer (that poses great suggestions!) to help you identify and fix problem areas in your JavaScript where a variable's type is anticipated but can't be safely assumed, resulting in a spawling mass of C code to cover every JavaScript edge case.
* *Nina* minimizes the use of language extensions so that your code can run in the normal language's runtime/compiler just as well as in Nina.
* Great (TREMENDOUS) care has been taken to include *only what you used* in the transpiled code. This is most apparent at the default `-O0`, which optimizes for readability/inspection.

* What separates Nina's C to JavaScript from Emscripten and WASM?<br>Readability and code size. Nina's C to JavaScript functionality doesn't work for all C code, but, when it does work, the output is *very* readable, *very* feels-like-JavaScript, and is not just a C runtime environment in disguise.

#### Windows users: if you really must use the microshit compiler, don't expect to get much mileage at all out of your program.
Performance will be abysmal, as Nina relies heavily on compiler optimizations.

## TL;DR Gimme Maximum Speed JavaScript

Okay!, to read the minimum amount of this documentation, skip the bla-bla-bla lecture about bla-bla-profiling-bla-bla-benchmarks-bla-bla, and get the max performance possible, follow these steps:

1. Use a Linux distro with the GCC compiler installed. (Optionally set up large pages for even better performance.)
    * If your code does lots of file/network I/O, install libuv. On Ubuntu and derivatives (Linux Mint): `apt install libuv1-dev`
2. Keep re-running `nina -Wall your-js-main.js -o js-main.c` and fix your JavaScript code to resolve all the warnings. These warnings may seem pedantic and stupid but they will maximize performance and keep your code safe from Nina's [6 behavioral deviations from ECMAScript](#6-deviations).
    * **IMPORTANT CONCEPTUAL EXPLANATION OF NINA (MUST READ):** Nina is neither a separate language from JavaScript nor JavaScript plus lots of extensions; instead *it is JavaScript*. (Actually, Nina is technically TypeScript, which is JavaScript plus optional type annotation syntax. All ordinary JavaScript is valid TypeScript.)
        * The way Nina suggests you rewrite your code utilizes uncommon syntaxes that already exist in normal, ordinary JavaScript. With these modifications to your code, your code will still be ordinary JavaScript that runs fine in NodeJS or in the browser.
        * The `-Wall` suggested modifications make your JavaScript code run in a *special way* that prevents crazy edge cases and enables Nina to *safely* rewrite your JavaScript into efficient C code that still exhibits all the same behavior as if it were normal, ordinary JavaScript.
        * If you do not fix the warnings from `-Wall`, Nina can still transpile your JavaScript to C, but it will be a much larger sprawling mass of C code in otder to handle every crazy JavaScript edge case that's unlikely to happen.
    * Once you get the hang of the warnings and get in the flow, be sure to read the [`-fjsdouble` / `-fno-js-double`](#js-doubles) section to understand how temporary floating points and Nina's  transpire-time Math macros work. This will make your life A LOT easier and less confusing!
3. Enable ALL the performance options, including the drastic massive-complexity ones and the ones that may make the C unportable between CPU architectures and only support GCC:

    `nina -Wall your-js-main.js -o js-main.c -Ofast -fno-aggressive-rtti-args -fwhole-program -fjs-gc-thread -fc-no-pic -fuse-large-pages -fc-linked-math -fuse-compressed-oops -fassume-48bit-vspace -fassume-gnuc `
    * If your code does lots of file/network I/O, add `-fjs-use-libuv-event-loop`
    * If your code is a long-running service (e.x. http server), add `-fc-pgo-cli-helper`
    * If your code can tolerate it, you can try adding `--utf=8`. This will make all strings in JavaScript UTF8 instead of the usual UTF16 (`--utf=16`) such that strings act like a Uint8Array. That is, `.charCodeAt` will only return bytes (0 to 255) and Emojis in strings take up 4 characters instead of 2.
    
4. Compile with GCC and these flags to do PGO (profile-guided-optimization):

    `gcc js-main.c -o js-main -pthread -DNDEBUG -pipe -Ofast -fwrapv -fweb -frename-registers -floop-nest-optimize -march=native -mtune=native -mlam=u48 -mno-avx -mno-avx2 -mdaz-ftz -mfpmath=sse -fno-align-labels -fno-align-jumps -falign-functions=4096:64:64:8 -falign-loops=64:8 -fno-version-loops-for-strides -fmerge-all-constants -fmodulo-sched -fmodulo-sched-allow-regmoves -fno-asynchronous-unwind-tables -fipa-pta -fvect-cost-model=very-cheap -fno-pic -fno-pie -Wl,-no-pie -Wl,-z,now -Wl,-z,relro -mtls-dialect=gnu2 --param max-rtl-if-conversion-insns=18 --param max-rtl-if-conversion-predictable-cost=36 --param max-rtl-if-conversion-unpredictable-cost=72 --param max-vartrack-expr-depth=30 --param max-tail-merge-comparisons=100 --param max-tail-merge-iterations=30 --param max-hoist-depth=300 --param gcse-unrestricted-cost=1 --param gcse-cost-distance-ratio=50 --param max-stores-to-sink=16 --param max-stores-to-merge=4096 --param predictable-branch-outcome=33 -fprofile-generate -Wl,-fprofile-generate`
    * If you used `-fjs-use-libuv-event-loop` (as your code does lots of file/network I/O), add `-luv` to the end (not the start!)
    * If GCC complains about an *unrecognized command line option*, simply remove that unrecognized option and continue. You may have an old version of GCC or future versions of GCC may remove some of these options.
    * For a little bit more performance, you can disable two recommended security features by adding `-fno-stack-protector -fno-stack-clash-protection` to the end
    * (Side note: the generated `js-main.c` may be many many megabytes in size, so compilation may take some time.)

5. Your program was compiled in *profiling* mode and GCC will instrument how it runs so that it can superoptimize it later via PGO.
    * IF you have a one-and-done CLI program, run `./js-main` with a variety of different arguments, options, and input/output files you would normally expect it to handle. Stretch its legs so that GCC can profile what its doing.
    * IF you have a long-running service (and used `-fc-pgo-cli-helper` in step #3), then run `./js-main --nina-pgo-run-for=60 --nina-pgo-clock-speedup=1000` (plus a variety of CLI options your program accepts) to simulate your program's perception of time running 1000x faster and *gracefully* end your service after 60 seconds (to ensure the PGO data is saved). During these 60 seconds, make a variety of requests to your service to stretch its legs and let GCC profile its normal operation.

6. Recompile the generated C, replacing `-fprofile-generate` with `-fprofile-use`, to use the PGO data from the last step:
    
    `gcc js-main.c -o js-main -pthread -DNDEBUG -pipe -Ofast -fwrapv -fweb -frename-registers -floop-nest-optimize -march=native -mtune=native -mlam=u48 -mno-avx -mno-avx2 -mdaz-ftz -mfpmath=sse -fno-align-labels -fno-align-jumps -falign-functions=4096:64:64:8 -falign-loops=64:8 -fno-version-loops-for-strides -fmerge-all-constants -fmodulo-sched -fmodulo-sched-allow-regmoves -fno-asynchronous-unwind-tables -fipa-pta -fvect-cost-model=very-cheap -fno-pic -fno-pie -Wl,-no-pie -Wl,-z,now -Wl,-z,relro -mtls-dialect=gnu2 --param max-rtl-if-conversion-insns=18 --param max-rtl-if-conversion-predictable-cost=36 --param max-rtl-if-conversion-unpredictable-cost=72 --param max-vartrack-expr-depth=30 --param max-tail-merge-comparisons=100 --param max-tail-merge-iterations=30 --param max-hoist-depth=300 --param gcse-unrestricted-cost=1 --param gcse-cost-distance-ratio=50 --param max-stores-to-sink=16 --param max-stores-to-merge=4096 --param predictable-branch-outcome=33 -lm -fprofile-use -Wl,-fprofile-use`
    * If you used `-fjs-use-libuv-event-loop` (as your code does lots of file/network I/O), add `-luv` to the end (not the start!)
    * If you previously used `-fno-stack-protector -fno-stack-clash-protection`, you must specify these again! The compile options must be the same!
    
7. Now, you have a super-duper-ultra-fast compiled JavaScript program eager to impress you and utterly blow your socks off: `./js-main` 





## <a name="6-deviations"> IMPORTANT: Deviations from Standard ECMAScript that Nina has</a>

Educate yourself on these because these four most-always-true assumptions are the fundamental basis for Nina's optimizations. They cannot be disabled because, then, Nina would be forced to generate crappy transpiled code and that would defeat Nina's entire purpose. So, use NodeJS if these don't work for you.

### 1. Type Conversions are Pure

This implies four quirks:

1. `""+x` and `+x` (which invoke `.toString` and `.valueOf`, respectively) are assumed to have no sideeffects and can be discarded if the result isn't used.
2. `""+x` and `+x` (which invoke `.toString` and `.valueOf`, respectively) are assumed to always return the same value if the object hasn't been modified.
3. Manual calls to `.toString` and `.valueOf` are assumed to *be impure but have no sideeffects.* That is, they may return different values every time but do not change the state of the program in any way, so they can be discarded if the result is not used. Example uses include calling `.toString` on an array every time you modify its contents.
4. `void expression;` can be used to explicitly tell Nina that the expression is impure and has sideeffects.

For example, take the following JavaScript code:

```js
// BAD JavaScript example of code with impure type conversions
var myObj = {
    toString() {
        console.log("Hello world!");
    }
};
"" + myObj;
myObj.toString();
```

At `-O1` (or, manually, `-feliminate-dead-code`), this yields the following C code:


```c
// generated C code from BAD JavaScript with mpure type conversions
// (empty! no C code generated!)
```

Nina completely optimized away the code as it saw no need for the return values! The best solution is to rewrite the code to not do work in type conversions. Alternatively, we can use ``void`:

```js
// DISCOURAGED JavaScript code that does work correctly
var myObj = {
    toString() {
        console.log("Hello world!");
    }
};
void "" + myObj;
void myObj.toString();
```

Next, we can see Nina caching a stringified object in a loop:

```js
// BAD JavaScript code that DOES NOT WORK in Nina
var myObj = {
	valueOf() {
		return Math.random() * (2**32) | 0
	}
};
for (var i=0; i < 4; i++)
    console.log( Number(myObj) );
```

At all optimization levels in Nina, this yields the following console output:

```js
-255164919
-255164919
-255164919
-255164919
```

(Note that `-fcrypto-random` is recommended so that Nina can seed its random state with the OS's high quality random number generator at startup.)

### 2. Builtin APIs cannot be modified

If the transpiler catches you, the program will fail to transpile. If it doesn't, the program will abort when you try to modify a builtin API. For example:

```js
// Example of BAD code that will FAIL to transpile
Array.prototype.sliceInHalf = function() {
	return this.slice(0, this.length >> 1);
};
```

Nina won't accept the above code or anything else that modifies the natives in any way. There is *one* exception&mdash;the common polyfill idiom: 

```js
// Example of OK code that will SILENTLY BE IGNORED by Nina
Array.with = Array.with || function(i, n) {
	var copy = this.slice();
	copy[i] = n;
	return copy;
};
```

Nina will NOP this idiom when it sees it.

### 3. Builtin APIs cannot be iterated

They cannot be iterated because they *might be missing* (if Nina determined the API isn't used by your code), so permitting iteration would open all sorts of cans of worms. That is,

* No global property, whether its a dictionary like `Math`, an instance like `console`, or a constructor like `Array`, can be iterated
* ``prototype`s of constructors cannot be iterated

```js
// Example of BAD code that will FAIL to transpile
console.log( Object.keys(Array.prototype) );
```


### 4. Integer overflow is assumed to never happen

With the default `-fno-doubles` to disable floating points (except in temporary ephemeral expressions&mdash;[see here](#fjs-doubles)), all JavaScript numbers are stored as integers. For significantly better codegen, Nina dances with the definition of an integer such that it considers all addition and subtract to yield integers and uses 64-bit integers instead of `double`s to silently sweep the overflow under the rug where you shouldn't ever have to see or worry about it.

Yet, it's still there, lurking in the shadows. If you perform repeated addition upon numbers or add 2<sup>31</sup>-1 to a number more than 2<sup>31</sup>+2 times, the 64 bit integer will overflow and be all kinds of whack. Observe:

```js
// BAD JavaScript example snippet showing integer overflow manifesting
var a = 2147483647, b = 2147483647;
function double() {
	a += b;
	b = a;
}
function printA() {  
	// using `a` from a lexically scoped context is necessary to box it up.
	// using `a` from the same context overflows at 2**63-1, not 2**62-1.
	console.log(a);
}
for (var i=0; i < 31; i++) double();
printA(); // correctly prints 4611686016279904000
a += 2147483647;
a += 2147483647;
a += 2;
printA(); // wrongly prints -4611686016279904000
```

Note that this problem shouldn't ever manifest in your code, but, to be safe, I highly recommend `-Wstrict-ints` to enforce coercion of all addition and subtraction. Nina is very intelligent and forces you to coerce any multiplication or division to an integer to ensure it stays within the acceptable range. This is just a minor important quirk of Nina to be aware of. For example:

```js
// This JavaScript FAILS to transpile, erring that `x * 3` must be coerced to an integer via `|0`
function mulBy3(x) {
    return x * 3;
}
```

With `-Wstrict-ints`, Nina will prompt you to change the first snippet to coerce all additions and subtractions to bitwise int32s:

```js
// GOOD JavaScript example snippet showing proper int coercion
var a = 2147483647, b = 2147483647;
function double() {
	a = a + b | 0;
	b = a;
}
function printA() {
	console.log(a);
}
for (var i=0; i < 31; i=i+1|0) double();
printA(); // correctly prints -2147483648
a = a + 2147483647 | 0;
a = a + 2147483647 | 0;
a = a + 2 | 0;
printA(); // correctly prints -2147483648
```

Then, this code will behave exactly the same in Nina and NodeJs.


### 5. `eval` and friends are unavailable

Nina transpiles only the minimum necessary for the JavaScript to run and nothing else (e.x. a full JavaScript interpreter). 

So, you can forget about any ability to execute new JavaScript code at runtime.

Technically, Nina does offer a way to bundle its library version&mdash;libnina&mdash;in with your code at the cost of several megabytes of extra code and the requirement compatible GPL licensing. This GPL requirement never applies to your code normally generated by Nina. See [License](#license) for more info.

### 6. All JavaScript is in strict mode

Regardless of whether you explicitly put `"use strict";` at the top of your code, Nina always assumes its there and has no support for sloppy-mode JavaScript code. If you need sloppy mode, use NodeJs.

See [the MDN on strict mode](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Strict_mode#transitioning_to_strict_mode) for further reading.

# Documentation and help

### HELP! Nina isn't working and is spitting out lots of error messages

Please learn how to read English. A core crux of Nina's design is printing readable error messages and suggestions for how to fix them.

That's right: all you have to do is overcome your ADD/ADHD/Dyslexia and *just read*.
If you do read AND the message is still unclear AND you know more than basic JavaScript, then that's the time to open a bug report.
The devs always eagerly looking for ways to improve the clarity and usefulness of the errors messages.

If you are a novice lacking experience in JavaScript, I highly recommend abandoning Nina and using NodeJS instead. Copying poorly written JavaScript snippets from StackOverflow is very likely to trigger one of the edge cases that Nina optimizes out (e.x. modifying native prototypes by adding `Array.prototype.randomizeOrder`, assuming code points are UTF-16, etc.) and you won't have the knowledge to understand, identify, and correctly solve when these arise. Nina's suggestions are only correct about half the time: they mainly serve as an example for how to structure/rearrange your code to make Nina happy; a solid understanding of JavaScript is necessary to understand the behavior at play and make correct decisions.

### <a name="event-loop-and-integrating-js">Event loop and integrating JS into your C/C++ project</a>

Steps:

1. `nina your-js-lib.js -o your-js-lib.c -o your-js-lib.h -shared` (notice the `-shared` flag, which disables generating an `int main(){...}` and adds a few helper utilities.)
2. Setup your C/C++ code as follows:

    ```c
    // File:    main.c
    // Compile: cc -o main main.c your-js-lib.c -O3
    #include "your-js-lib.h"
    
    int main() {
        while (1) {
            uint64_t nextScheduledTimeNs = ninaEventLoop(); // returns UINT64_MAX if event loop is empty or there's only pending I/O
            
            // run your C code here to do stuff with the JavaScript every tick
            
            if (ninaEventLoopSize() == 0) break; // no more work to do. The program is finished!
            
            ninaSleepUntilNs( nextScheduledTimeNs );
        }
        return 0; // then, Nina's atexit hook runs finalizers and clean-up stuff
    }
    ```
    
    (IMPORTANT: it's crucial you call `ninaEventLoop` at least once before doing anything with the JavaScript. This will ensure the Nina state is setup properly and all JavaScript setup code is run. It will also block and sleep for any top-level `await` until the top level is fully executed.)
    
    (Side note about `ninaExit`: if any finalizer schedules more work on the event loop, Nina will keep sleeping and blocking the exit and running the event loop until everything finishes up.)
    
    (Side note: use `ninaSleepUntilNs` instead of your own sleep method to skip sleeping if there's pending work and wake up early for completed I/O operations or use `nextScheduledTimeNs - ninaTimeNowNs()` to get the relative time in nanoseconds to pass to your own sleep method. Make sure to clamp the slept time to, say, 50ms for example. See [event Loop C API](#event-loop-c-apis).)

3. Compile your project with `cc -o main main.c your-js-lib.c -O3` and run with `./main` and that's all!

See [the C api section](#c-apis) for more info and a full example on interoperating between JavaScript and C.

### `nina2c`&mdash;the JS->C transpiler


### Expressive C Code


For example, take the following JavaScript constructor:

```js
function Vector3(x, y, z) {
    this.x = x;
    this.y = y;
    this.z = z;
}
```

This produces the following C code:

```c
typedef struct Vector3 {
    JSObject __proto__;
    uint64_t x;
    uint64_t y;
    uint64_t z;
} Vector3_t;

uintptr_t Vector3_new(uintptr_t this, uintptr_t x, uintptr_t y, uintptr_t z) {
    
}

uintptr_t Vector3(uintptr_t this, uintptr_t x, uintptr_t y, uintptr_t z) {
    jsSet
}
```


### Intelligent deductions and optimistic inferences

Observe the following JavaScript:

```js
// Source JavaScript for this example
function printHelloWorldNTimes(len) {
    for (var i=0; i < len; i++) {
        console.log("Hello world times " + i);
    }
}
```

With default options, Nina transpiles this to the neat, compact C code below:


```c
// Generated C with default options
// This program RUNS FINE and exhibits the exact behavior it's supposed to
NinaValue_t printHelloWorldNTimes(void* ninaCTX, const void* lenType, uint64_t lenValue) {
    int64_t lenI64 = ninaToInt(JSOPT_DECIMALERROR_INTMAX | JSOPT_RANGEERROR_INTMAX, lenType, lenValue, /*if NaN:*/0);
    
    for (int64_t iI64=0; iI64 < lenI64; iI64++) {
        printf("Hello world times %" PRIi64 "\n", iI64);
    }
    return jsPrimitiveUndefined;
}
```

Notice `JSOPT_DECIMALERROR_INTMAX | JSOPT_RANGEERROR_INTMAX`:

* `JSOPT_DECIMALERROR_INTMAX` and `JSOPT_RANGEERROR_INTMAX` tell `ninaToInt` to return `INT64_MAX` or `INT64_MIN` if `lenValue` can't be exactly represented as an integer&mdash;considered an *error*&mdash;due to having a decimal or being too large for the 52-bit double-precision's significand (that `Number.isSafeInteger(i)` is `false`).
    * Positive errant floats yield `INT64_MAX`; negative yield `INT64_MIN`.
    * Nina recognizes that `i` will only ever be an integer because the only operation upon it&mdash;`iI64++`&mdash;only yields integers. So, if `len` has a decimal or `Number.isSafeInteger(i)` is `false`, the loop will never terminate, which is simulated by using the max value of the 64-bit integer.
    
Notice the `/*if NaN:*/0`:

* Nina sees the `iI64 < lenI64` condition and determines that, if `i` evaluates to `NaN` in `valueOf`, then `iI64 < lenI64` will *always* be false.
* Thus, to simulate the `NaN` behavior, Nina tells `ninaToInt` to make `len` become the terminating condition of the loop&mdash;zero&mdash;if it is `NaN` in the integer conversion.
* For example, if you started the loop at `var iI64=123`, then the terminating condition would be one and Nina would emit `/*if NaN:*/123` instead.

<!--Notice the `JSOPT_STRING_FIRSTCHAR` option. If `valueOf` upon `len` yields a string, then that entirely changes the behavior of the code. Then, every `i < len` will `toString` upon `i` and compare them as strings, not as integers. For example, `2 < 13` is obviously `true`, but `"2" < "13"` is oddly `false` because `"2".charCodeAt(0) > "13".charCodeAt(0)`. Thus, we extract the first number from the string and iterate until we reach that number.-->

### Typed variables and cast-enforced typing yield excellent codegen

Observe the innocent-looking JavaScript below:

```js
// Example initial JavaScript code
function aPlusB(a, b) {
    return a + b;
}
```

Nina is forced to transpile this JavaScript into the sprawling mass of C code below in order to correctly handle strings. E.x. `addAPlusB("one","two")` must yield `"onetwo"`.

```c
// Generated C with default options (note: doubles are disabled by default: `-fno-js-doubles`)
// This program IS GOOD and exhibits correct behavior
NinaValue_t aPlusB(void* ninaCTX, const void* aType, uint64_t aValue, const void* bType, uint64_t bValue) {
    NinaValue_t a = {aType, aValue};
    NinaValue_t b = {bType, bValue};
    if ((ninaTypeMask(a.type) & ninaTypeMask(b.type) & NINATYPEMASK_INT) != 0) {
        // (Note: This fastpath speeds up the case where a is an int and b is an int)
        return (NinaValue_t) {NINATYPE_INT, a.value + b.value};
    } else {
        // (Note: This is the fallthrough slow path. Nina is optimistic that this path won't be taken)
        return ((NinaRtti_t *) a.type)->opAdd(/*options:*/0, a.type, a.value, b.type, b.value);
    }
}
```


The particular case shown above is rather decent actually. Nina intelligently observes how the only operation possibly requiring memory allocation (in the event of massive strings that can't fit in the small heap stack) is returned from the function, so it eliminates setting up a stack bookmark&mdash;`ninaGcMarkStackMACRO` and `ninaGcFreeStackMACRO`&mdash;, which effectively causes the allocated memory to be owned by the caller function and freed when the caller exits.

Let's make the generated C code even better. Enter typescript-like variable typing:

```js
// Example typescript-like typing
function aPlusB(a: i32, b: i32): i32 {
    return a + b;
}
```

Explicitly specifying the types of `a` and `b` above to both be 32-bit signed integers enables Nina to produce the clean code below which has only the overhead of a single type-check-and-branch. IMPORTANT: `i32` is not a valid type in TypeScript, so see the [Compatibility](#Compatibility) below for how to make your code run in both Nina and TypeScript.

```c
// Generated C for the cast-enforced types example
// This program IS GOOD and exhibits correct behavior
NinaValue_t aPlusB(void* ninaCTX, const void* aType, uint64_t aValue, const void* bType, uint64_t bValue) {
    if ((ninaTypeMask(aType) & ninaTypeMask(bType) & NINATYPEMASK_INT) != 0) jsThrowTypeError("aPlusB","i32,i32",aType,bType);
    
    return (NinaValue_t) {NINATYPE_INT, (int32_t)aValue + (int32_t)bValue};
}
```


Alternatively, a less efficient method is to cast the arguments to the desired type like so. 

```js
// Example cast-enforced types
function aPlusB(a: i32, b: i32) {
	a |= 0; // coerce to int
	b |= 0; // coerce to int
    return a + b;
}
```

Doing `a |= 0;` (equivalent to `a = a | 0;`), coerces `a` into a 32-bit integer for the bitwise-or operation against zero. This empowers Nina to make some awesome optimizations:

```c
// Generated C for the cast-enforced types example
// This program IS GOOD and exhibits correct behavior
NinaValue_t aPlusB(void* ninaCTX, const void* aType, uint64_t aValue, const void* bType, uint64_t bValue) {
    int32_t a = (int32_t) ninaToInt(JSOPT_DECIMALERROR_TRUNCATE | JSOPT_RANGEERROR_ZERO | JSOPT_RANGE_I32, aType, aValue); // coerce to int
    int32_t b = (int32_t) ninaToInt(JSOPT_DECIMALERROR_TRUNCATE | JSOPT_RANGEERROR_ZERO | JSOPT_RANGE_I32, bType, bValue); // coerce to int
    return (NinaValue_t) {NINATYPE_INT, a + b};
}
```

Use `-Wuntyped` to print warning messages about untyped areas of your code and suggestions for how to fix them. Use `-Werror` to turn these warnings into errors.

### Known Types

Below is a table of recognized type conversions that will satisfy Nina's need to know the type of the variable: 

|Type |Quantity|
|-----|--------|
|Apple|3       |
|Egg  |12      |

<!--This is particularly important for double-precision floating point values. For example, take the following Javascript:

```js
// Sample JavaScript
function add(a, b) {
    return a + b;
}
```

Nina produces the following C code from this JavaScript to handle all cases:

```c
// Sample resulting C
uintptr_t add(uintptr_t this, uintptr_t a, uintptr_t b) {
	if (jsIsInt(a & b)) {
		return (a + b) | JSintMask;
	} else {
		double a_double;
		uintptr_t a_valueOf = NinaValue_tOf(JS_OPT_CLONE, a, &a_double);
		if (jsIsString(a_valueOf)) {
			uintptr_t tempString = jsToString(JS_OPT_CONSUME, b, a_valueOf);
			return tempString;
		}
		double b_double;
		uintptr_t b_valueOf = NinaValue_tOf(JS_OPT_NORMAL, b, &b_double);
		uintptr_t tempResult = jsPolyType_add(JS_OPT_CONSUME, a, b, &a_double, &b_double);
		if (b != b_valueOf) jsFree(JS_OPT_NONE, b_valueOf);
		return tempResult;
	}
}
```

However, the following JavaScript produces much better code:


```c
// Sample JavaScript #2
function add(a, b) {
	a |= 0, b |= 0;
	return a + b | 0;
}
```

This second case guarentees that a and b will be integers, not bigints or proxies or such, yielding the followng:


```c
// Sample resulting C #2
uintptr_t add(uintptr_t this, uintptr_t a, uintptr_t b) {
	if ( ! jsIsInt(a & b)) {
		a = (int64_t)(int32_t)ninaToInt(JS_OPT_NONE, a);
		b = (int64_t)(int32_t)ninaToInt(JS_OPT_NONE, b);
	}
	return (int64_t)(int32_t)(a + b) | JSintMask;
}
```

This results in the following neat, compact x86 assembly in GCC:

```asm
add:
        push    rbp
        mov     rax, rdi
        mov     rbp, rsi
        push    rbx
        and     rax, rsi
        mov     rbx, rdi
        shr     rax, 61
        sub     rsp, 8
        cmp     rax, 7
        je      .L2
        call    ninaToInt@PLT
        mov     rdi, rbp
        movsx   rbx, eax
        call    ninaToInt@PLT
        movsx   rbp, eax
.L2:
        lea     eax, [rbx+rbp]
        add     rsp, 8
        movabs  rdx, -2305843009213693952
        cdqe
        pop     rbx
        pop     rbp
        or      rax, rdx
        ret
```

### Nina v.s. JavaScript

There are some important differences from normal JavaScript:

1. Integers are 64-bit and do not bounds check down to double precision floating point numbers. So, in certain rare circumstances, your numbers may have extra precision they normally wouldn't have.

2. -->

# Nina Language Extensions/Quirks

Nina attempts to keep all language extensions to a minimum where significant performance boosts can be achieved. Here's a list of special behaviors Nina implements to help you optimize your JavaScript to the max.

## `if (!(this instanceof <constructor>)) throw <error>;`

**What:** guarantees that a function can only be used as a constructor, which reduces code sizes by eliminating generating a slow-path variant to handle non-constructor function calls

**Fallback:** none needed! This is valid JavaScript.

**Scope:** works best when put at the *very top* of the constructor. Also works later in the constructor as a cut-off but less well.

With `if (!(this instanceof <constructor>)) throw <error>;`, Nina doesn't have to generate a version of the function to handle non-constructing calls. Observe:

```js
// Example JS #2 of `if (!(this instanceof <constructor>)) throw <error>;`
function OneAndTwo() {
	if (!(this instanceof OneAndTwo)) throw 0;
	this.one = 1;
	this.two = 2;
}
```

This is the default behavior for classes, so you can choose either route to get the same result:

```js
// Example JS #2 of `if (!(this instanceof <constructor>)) throw <error>;`
class OneAndTwo {
	constructor() {
		this.one = 1;
		this.two = 2;
	}
}
```

The generated C code is the same in both cases:

```js
// Example JS #2 of `if (!(this instanceof <constructor>)) throw <error>;`
class OneAndTwo {
	constructor() {
		this.one = 1;
		this.two = 2;
	}
}
```

**IMPORTANT NOTE**: `if (!(this instanceof <constructor>)) throw <error>;` actually has no effect on the above trivial code snippet as Nina can statically analyze that the properties will never change and applies the same optimizations automatically. It's highly recommended you inspect your JavaScript's resulting C code and see where you need to fix things. Or, use `-Wobjects` for Nina to point them out to you.

## `Object.unorderAndSeal` (macro)

**What:** `Object.seal` PLUS the order of `Object.keys` is *undefined* and at the whims of *Nina*.

**Fallback:** use `(Object.unorderAndSeal || Object.seal)(x)` for backwards compatibility

**Scope:** only usable in the same context the object was created. This is particularly useful at the end of constructors to improve performance and save memory.

With `Object.unorderAndSeal`, Nina can freely represent the object as a high-performance low-memory C `struct` because it's guarenteed no properties will be added/removed AND no metadata about the order of the properties has to be stored.


```
// Example JS usage of `Object.unorderAndSeal`:
function Dog({age, weight}) {
	if (!(this instanceof Dog)) throw 0;
	
	this.age = age;
	this.weight = weight;
	
	(Object.unorderAndSeal || Object.seal)(this);
}
console.log((Object.unorderAndSeal || Object.seal)(new Dog()));
```

Yields this amazingly compact C code that can provably handle all the same behavior as the JavaScript:

```c
// Generates C from `Object.unorderAndSeal` example:
```

**IMPORTANT NOTE**: `Object.unorderAndSeal` actually has no effect on the above trivial code snippet as Nina can statically analyze that the properties will never change and applies the same optimizations automatically. It's highly recommended you inspect your JavaScript's resulting C code and see where you need to fix things. Or, use `-Wobjects` for Nina to point them out to you.


## 32x32->hi32 multiplication

```js
// setup code to get 32x32->hi32 multiplication
function imulHigh32(x, y) {
	return Math.floor((x|0) * (y|0) / 4294967296) | 0;
}
```

**What:** A counterpart to `Math.imul` that returns the high 32 bits of 32x32 multiplication instead of the low 32 bits.

**Fallback:** none needed; it's plain JavaScript.

**Scope:** usable anywhere! Nina supports floating point math inside of temporary expressions with `Math.floor` as a transpile-time macro. And, when it sees two integers multiplied, divided by 2<sup>32</sup> (or a lesser power of 2), and `Math.floor`ed, it optimizes this floating point math to high 32-bit integer multiplication.

Here's the generated C code for that `imulHigh32` method:

```c
// generated C code for the `imulHigh32` example
function imulHigh32(x, y) {
	return Math.floor((x|0) * (y|0) / 4294967296) | 0;
}
```

**IMPORTANT:** Nina explicitly forbids the modification of any built-in API. Trying to do `Math.imulHigh32 = function(){...}` will result in a transpile-time error. There is no flag to turn this off; you'd just have to forgo using Nina.

## 64-bit integers

```js
// setup code to get 64-bit integers
var i64 = BigInt.asIntN.bind(null, 64);
var u64 = BigInt.asUintN.bind(null, 64);
```

**What:** high-performance 64-bit integers for you.

**Fallback:** none needed. This is ordinary JavaScript.

**Scope:** all 64-bit values must be coerced to *signed* 64-bit integers via `i64(x)` prior to being assigned anywhere, passed as an argument, or returned from a function. *Unsigned* 64-bit integers via `u64(x)` can only be used temporarily in expressions and must be cast back to *signed* before being stored anywhere. 

HowTo cast int64 between various value types:

|   From `x`     |     To `y`     | Conversion Code |
| -------------- | -------------- | --------------- |
| int32          | int64          | `y=BigInt(x)` (or <code>y=BigInt(x&#124;0)</code> if Nina can't prove `x` is int32) |
| int64          | int32          |  <code>y=Number(x)&#124;0</code> |
| temporary float| int64          | `y=i64( BigInt( Math.round(performance.now() * 1000000) ) )`<sup>&dagger;</sup> |
| int64          | temporary float| <code>Number(x)</code><sup>&dagger;</sup> |
| string         | int64          | `y=i64(BigInt(""+x))`<sup>&ddagger;</sup>, `y=i64(BigInt("0x"+x))` (hex), or `y=i64(BigInt("0b"+x))` (bin) |
| int64          | string         | `y=""+x`, `y=""+u64(x)` (unsigned), `y=u64(x).toString(16)` (hex), etc. |

<sup>&dagger;</sup> Note: temporary floating point expressions exist *ephemerally* and cannot be stored anywhere. When converting a temporary float to an int64, Nina accepts any Math macro that removes the decimal: `Math.trunc`, `Math.floor`, `Math.ceil`, or `Math.round`. See [`-fjs-doubles` / `-fno-js-doubles`](#fjs-doubles) for details on temporary floating point expressions.

<sup>&ddagger;</sup> You can use `y=i64(BigInt("0"+x))`to *force* parsing the string in base10 to an int64 or error out if its invalid base 10. This is recommended for untrusted user input so that `0x` hexadecimal and `0b` binary are rejected.

Addendum: for a 64-bit constant, append `n` to mark it as a BigInt like so: `0xda942042e4dd58b5n`

**IMPORTANT:** support for 64-bit integers is SEPARATE from support for general BigInts (enabled with `-fjs-bigints`). Nina uses type-checking to optimize 64-bit bigints into `int64_t` or `uint64_t` in C, whereas arbitrary size BigInts require SIGNIFIGANTLY more overhead and code and are disabled by default.

Due to only being able to store *signed* 64-bit integers, only `BigInt64Array` is available and `BigUint64Array` is disabled. (The `BigUint64Array` is only enabled with general arbitrary-size bigint and it can be SIGNIFIGANTLY slower, allocating an object every fucking access whenever the value is over 2<sup>62</sup>-1. That's 75% of all possible `uint64_t`!!!)

**Caveat:** Values below -2<sup>62</sup> and above 2<sup>62</sup>-1 cannot be stored inline and will escalate to the same performance degradation as 32-bit integers in 32-bit compressed boxes: using a global interning hashmap to store the integers as objects. Here's when the pitfall occurs:

* Returning large int64 values or passing them as argument never boxes them, so there will be no performance pitfalls.
* Storing large int64 in local variables (EXCEPT lexically-scoped variables) will never box them, avoiding the pitfall.
* Storing large int64 in `BigInt64Array` also avoid the performance pitfall.
* All other use and storing them anywhere else will definitely incur the performance pitfall unless `-fno-compressed-value-boxed` is specified to turn off all boxing.

To avoid this performance pitfall, you have three options:

1. Only use 64-bit integers in local variables (which are always unboxed and will never have performance issues) and either use `BigInt64Array` OR break them apart into 32-bit values when storing them in objects:

    ```js
    // TimeStampNanoSeconds JavaScript example of performant int64s in Nina
    function TimeStampNanoSeconds( timeStamp ) {
        if (!(this instanceof TimeStampNanoSeconds)) throw 0;
        this.lo32 = Number( BigInt(timeStamp) ) | 0;
        this.hi32 = Number( BigInt(timeStamp) >> 32n ) | 0;
	    (Object.unorderAndSeal || Object.seal)(this);
    }
    TimeStampNanoSeconds.prototype.diff = function(other) {
        if (!(this instanceof TimeStampNanoSeconds)) throw 0;
        if (!(other instanceof TimeStampNanoSeconds)) throw 0;
        var thisTime = ((BigInt(this.hi32) << 32n) | BigInt(this.lo32);
        var otherTime = ((BigInt(other.hi32) << 32n) | BigInt(other.lo32);
        var diffTime = i64(otherTime - thisTime);
        return new TimeStampNanoSeconds( diffTime );
    }
    TimeStampNanoSeconds.now = function() {
        var ns = i64( BigInt( Math.round(performance.now() * 1000000) ) );
        return new TimeStampNanoSeconds(Number(ns)|0, Number(ns >> 32n)|0);
    };
    ```
    
    Observe how we subtract *signed* 64-bit time stamps above. Most operations are the same for signed and unsigned integers and it takes *zero* cpu cycles to convert between signed and unsigned (because signed and unsigned are bit-for-bit the same). That's why only allowing the storage of *signed* 64-bit ints isn't a big deal and really doesn't matter. *Beware* particularly of arithmetic right shift on negative numbers, which shifts in the top bit to fill the highest bits. `i64(x) >> 5` and `u64(x) >> 5` will be the same for positive integers but differ for negative integers. On the other hand, `Number(i64(x) >> 32)|0` and `Number(u64(x) >> 32)|0` will be the same for all integers because `|0` cuts off the lowest 32 bits and `>>32` upon a 64-bit integer shifts the top 32 down to the bottom 32. Then, `i64(x) >> 32` upon a negative number yields all 1s in the top 32 bits without effecting the low 32 and `u64(x) >> 32` sets all zeros in the top 32 bits regardless of sign.

2. OR, use the `-fno-compressed-value-boxed` CLI option. This may also improve performance in other areas of your code as well at the cost of ~40% increase in memory (maybe more).
3. OR, if you can just settle for 63-bit integers, you'll get just as good performance:

    ```js
    // setup code to get faster 63-bit integers
    var i63 = BigInt.asIntN.bind(null, 63);
    var u63 = BigInt.asUintN.bind(null, 63);
    // Nina also recognizes any size < 63 and applies the same logic as 63-bit
    var i37 = BigInt.asIntN.bind(null, 37);
    var u37 = BigInt.asUintN.bind(null, 37);
    ```
    
    **Caveat:** Nina will quietly allow unsigned `u63` to be stored directly in any object as all its possible values can fit within an `i64`, and thus introduce the same performance pitfalls for values above 2<sup>62</sup>-1. Use `i63` judiciously and/or `-Wint63-only` to warn when you store int63 anywhere.

One last important note: the internal representation of int64 is as plain integers. That's right: Nina makes no distinction whatsoever in how it stores int64s vs how it stores int32s. As a consequence, int32s can be (wrongly) accessed from objects as int64s and vice-versa. DO NOT DEPEND ON THIS BEHAVIOR! This is one of Nina's quirks and deviates severely from the JavaScript standard. Trying to do this in compliant JavaScript will throw an exception
    
```js
// transpiled C code from the TimeStampNanoSeconds JavaScript example
function TimeStampNanoSeconds( timeStamp ) {
    if (!(this instanceof TimeStampNanoSeconds)) throw 0;
    this.lo32 = Number( BigInt(timeStamp) ) | 0;
    this.hi32 = Number( BigInt(timeStamp) >> 32n ) | 0;
    (Object.unorderAndSeal || Object.seal)(this);
}
TimeStampNanoSeconds.prototype.diff = function(other) {
    if (!(this instanceof TimeStampNanoSeconds)) throw 0;
    if (!(other instanceof TimeStampNanoSeconds)) throw 0;
    var thisTime = ((BigInt(this.hi32) << 32n) | BigInt(this.lo32);
    var otherTime = ((BigInt(other.hi32) << 32n) | BigInt(other.lo32);
    var diffTime = i64(otherTime - thisTime);
    return new TimeStampNanoSeconds( diffTime );
}
TimeStampNanoSeconds.now = function() {
    var ns = i64( BigInt( Math.round(performance.now() * 1000000) ) );
    return new TimeStampNanoSeconds(Number(ns)|0, Number(ns >> 32n)|0);
};
```

Observe how this behavior manifests:

```js
var hashmap = {};
hashmap.prop = 1234567891000000000n; // int64
var asPlainInt = hashmap.prop;
asPlainInt -= 910; // should throw an exception for mixing bigint and int32s but it doesn't in Nina!
console.log(BigInt(asPlainInt)); // logs 1234567890999999090n
```

(Note that the `BigInt` inside the `console.log` is necessary to show all the digits of the number. Just `console.log(asPlainInt)` would log `1234567890999999000`, zeroing the lowest digits.)

As a consequence, the `typeof` operator doesn't work on int64s and you may receive errors:

```js
// BAD JS snippet that will fail to transpile, erroring that int64s cannot be distinguished from integers
function isInt64(x) {
    return typeof x === "bigint";
}
```

If you need to distinguish int64s from integers and have their type data associated with them, you must compile with `-fjs-bigints` for support for general arbitrary-size big integers. (This will also severely degrade performance.)

## Fast 128-bit multiplication (via 64-bit ints)


**What:** This is a continuation of the 64-bit integer section answering: *how much work can i do with an uncasted 64-bit integer expression before coercing it back into a 64-bit integer?*

**Fallback:** none needed. This is ordinary JavaScript.

**Scope:** all 64-bit integers can be used as part of 128-bit temporary expressions as long as the result is shifted down no more than 64 bits and casted to either `u64` or `i64`. Additionally, you *may* need to use `BigInt.asUintN(128, x)`, `BigInt.asIntN(128, x)`, and smaller (e.x. BigInt.asIntN(101, x)`) as part of temporary expressions to cut off the higher-than-128 bits for certain operations like shifting down and division. Shift down of 65-127 are allowed upon a cast-to-128 and shifts down of 128 or more constant evaluate to always zero. Apparently, negative down shifts upon BigInts become upshifts instead of throwing an error.

For, example, this enables us to implement [Lemire's fast RNG](https://lemire.me/blog/2019/03/19/the-fastest-conventional-random-number-generator-that-can-pass-big-crush/) in JavaScript:

```js
// Lemire's RNG in JavaScript
var i64 = BigInt.asIntN.bind(null, 64);
var u64 = BigInt.asUintN.bind(null, 64);
var g_lehmer64_state_a = 0x2a356ad7;
var g_lehmer64_state_b = 0xe0b309cb;
var g_lehmer64_state_c = 0x446a825b;
var g_lehmer64_state_d = 0xc0acdcb3; // 4x32-bit random ints to hold a 128-bit integer 

function lehmer64(out: Array) {
    var g_lehmer64_state_ab = BigInt(g_lehmer64_state_a) | (BigInt(g_lehmer64_state_b) << 32n);
    var g_lehmer64_state_cd = BigInt(g_lehmer64_state_c) | (BigInt(g_lehmer64_state_d) << 32n);
    var lo = i64((g_lehmer64_state_ab | (g_lehmer64_state_cd << 64n)) * 0xda942042e4dd58b5n);
    var hi = i64((g_lehmer64_state_ab | (g_lehmer64_state_cd << 64n)) * 0xda942042e4dd58b5n >> 64n);
    g_lehmer64_state_a = Number(lo)|0;
    g_lehmer64_state_b = Number(lo >> 32n)|0;
    out[0] = g_lehmer64_state_c = Number(hi)|0;
    out[1] = g_lehmer64_state_d = Number(hi >> 32n)|0;
}
```

The above code is *ridiculously* slow in NodeJs/V8/Firefox but *ridiculously* fast in Nina as you can see:

```c
// transpiled C of Lemire's RNG example
var i64 = BigInt.asIntN.bind(null, 64);
var u64 = BigInt.asUintN.bind(null, 64);
var g_lehmer64_state_a = 0x2a356ad7;
var g_lehmer64_state_b = 0xe0b309cb;
var g_lehmer64_state_c = 0x446a825b;
var g_lehmer64_state_d = 0xc0acdcb3; // 4x32-bit random ints to hold a 128-bit integer 

function lehmer64() {
    var g_lehmer64_state_ab = BigInt(g_lehmer64_state_a) | (BigInt(g_lehmer64_state_b) << 32n);
    var g_lehmer64_state_cd = BigInt(g_lehmer64_state_c) | (BigInt(g_lehmer64_state_d) << 32n);
    var lo = i64((g_lehmer64_state_ab | (g_lehmer64_state_cd << 64n)) * BigInt("0xda942042e4dd58b5"));
    var hi = i64((g_lehmer64_state_ab | (g_lehmer64_state_cd << 64n)) * BigInt("0xda942042e4dd58b5") >> 64n);
    g_lehmer64_state_a = Number(lo)|0;
    g_lehmer64_state_b = Number(lo >> 32n)|0;
    g_lehmer64_state_c = Number(hi)|0;
    g_lehmer64_state_d = Number(hi >> 32n)|0;
    return hi; // return values are never boxed, so this is performance-safe
}
```

**Caveat:** When Nina is forced to emit 128-bit arithmetic, it presently and quite dumbly just inserts `__uint128_t` or `__int128_t` with no compiler support checks or fall backs or anything. So, the code will only compile on 64-bit cpus with GCC or Clang at present. But, there are plans to (eventually) expand support. It's on my TODO list.

## Fast 128-bit division (via 64-bit ints)

```js
// Fast 128-bit division JavaScript example
function signed_divide128_by_64_no_overflow(dividendLo, dividendHi, divisor, retRem) {
	dividendLo = i64( dividendLo );
	dividendHi = i64( dividendHi );
	divisor = i64( divisor );
	if (i64((u64(dividendLo) | (dividendHi << 64n)) / divisor >> 64n))
	    throw 0; // tells nina to assume the division wont overflow, enabling the optimization
	var quotient = i64((u64(dividendLo) | (dividendHi << 64n)) / divisor);
	var remainder = i64((u64(dividendLo) | (dividendHi << 64n)) % divisor);
	return retRem ? remainder : quotient;
}
function unsigned_divide128_by_64_no_overflow(dividendLo, dividendHi, divisor, retRem) {
	dividendLo = i64( dividendLo );
	dividendHi = i64( dividendHi );
	divisor = i64( divisor );
	if (i64((u64(dividendLo) | (dividendHi << 64n)) / u64(divisor) >> 64n))
	    throw 0; // tells nina to assume the division wont overflow, enabling the optimization
	var quotient = i64((u64(dividendLo) | (dividendHi << 64n)) / u64(divisor));
	var remainder = i64((u64(dividendLo) | (dividendHi << 64n)) % u64(divisor));
	return retRem ? remainder : quotient;
}
```

**What:** if we can guarantee the result of a 128-bit integer divided by a 64-bit integer will fit into a 64-bit integer, we can use x86's ultra fast div instruction.

**Fallback:** none needed. This is ordinary JavaScript.

**Scope:** (see what)

Basically, asserting that the divsion won't overflow lets Nina optimize the `signed` and `unsigned` functions above into x86's `idiv` and `div`, respectively:


```js
// Generated C code for the 128-bit division JavaScript example
NinaValue_t signed_divide128_by_64_no_overflow(void* ninaCTX, const void* dividendLoType, uint64_t dividendLoValue,
        const void* dividendHiType, uint64_t dividendHiValue, const void* divisorType, uint64_t divisorValue,
        const void* retRemType, uint64_t retRemValue) {
    if (((uintptr_t)dividendLoType ^ (uintptr_t)NINATYPE_INT)
      | ((uintptr_t)dividendHiType ^ (uintptr_t)NINATYPE_INT)
      | ((uintptr_t)divisorType ^ (uintptr_t)NINATYPE_INT)) return jsThrowError("Argument is not a bigint");
	if (-((int64_t)divisorValue < 0)*(int64_t)divisorValue <= -((int64_t)dividendHi < 0)*(int64_t)dividendHi)
	    return jsThrowError("The result of 128bit division is too big to fit in an int64");
	int64_t quotientI64, remainderI64;
	#if defined(__GNUC__) && defined(__x86_64__)
	    __asm__("idiv{q    %[v]|    %[v]}" : "=a"(result), "=d"(remainderI64) : [v] "r"(divisorValue), "a"(dividendLoValue), "d"(dividendHiValue));
	#elif defined(_MSC_VER) && !defined(_M_ARM64)
	    quotientI64 = _div128(dividendHiValue, dividendLoValue, divisorValue, &remainderI64);
	#else
	    quotientI64 = (int64_t)((dividendLo | ((__int128_t)dividendHi << 64)) / (__int128_t)(int64_t)divisor);
	    remainderI64 = (int64_t)((dividendLo | ((__int128_t)dividendHi << 64)) % (__int128_t)(int64_t)divisor);
	#endif
	return (NinaValue_t) {ninaIsTruthy(retRemType, retRemValue) ? remainderI64 : quotientI64, NINATYPE_INT};
}
NinaValue_t unsigned_divide128_by_64_no_overflow(void* ninaCTX, const void* dividendLoType, uint64_t dividendLoValue,
        const void* dividendHiType, uint64_t dividendHiValue, const void* divisorType, uint64_t divisorValue,
        const void* retRemType, uint64_t retRemValue) {
    if (((uintptr_t)dividendLoType ^ (uintptr_t)NINATYPE_INT)
      | ((uintptr_t)dividendHiType ^ (uintptr_t)NINATYPE_INT)
      | ((uintptr_t)divisorType ^ (uintptr_t)NINATYPE_INT)) return jsThrowError("Argument is not a bigint");
	if (divisorValue <= dividendHi)
	    return jsThrowError("The result of 128bit division is too big to fit in an int64");
	int64_t quotientI64, remainderI64;
	#if defined(__GNUC__) && defined(__x86_64__)
	    __asm__("div{q    %[v]|    %[v]}" : "=a"(result), "=d"(remainderI64) : [v] "r"(divisorValue), "a"(dividendLoValue), "d"(dividendHiValue));
	#elif defined(_MSC_VER) && !defined(_M_ARM64)
	    quotientI64 = _udiv128(dividendHiValue, dividendLoValue, divisorValue, &remainderI64);
	#else
	    quotientI64 = (int64_t)((dividendLo | ((__uint128_t)dividendHi << 64)) / (__uint128_t)divisor);
	    remainderI64 = (int64_t)((dividendLo | ((__uint128_t)dividendHi << 64)) % (__uint128_t)divisor);
	#endif
	return (NinaValue_t) {ninaIsTruthy(retRemType, retRemValue) ? remainderI64 : quotientI64, NINATYPE_INT};
}
```


For further reading, see [this post by Danila Kutenin](https://danlark.org/2020/06/14/128-bit-division/)

# Pointer Compression

As prereading, I reccomend you look at the various commonly used [Data Model](https://sourceforge.net/p/predef/wiki/DataModels/).


The 64+-bit 



# Security Considerations

<!-->In my own opinion, Nina is entirely unsuitable as a sandbox to run untrusted code BUT it's very suitable for performing security-oriented operations:

* It's *guaranteed* that, no matter what optimization assumptions you apply, Nina will never generate C code that segfaults or leaks raw memory to the JavaScript EXCEPT when you have multithreaded code and do not use `-fthread-safe` and EXCEPT when you import or embed C code in the JavaScript.
    * For example, if you use the default `-fpure-type-casts` and errantly write code that modifies the program state from within type casts (thus making them non-pure), the only result will be incorrect program behavior, never errant C code.
* The tremendous use of branching (especially at `-Ofast`) based upon the *rtti type* of data, not the *contents* of the data, adds a significant degree of randomness to the execution time of the program, which *might* harden the program against side-channel attacks AS LONG AS you employ the typical careful considerations of branchless data manipulation methods upon the untrusted user input. No guarantees can be given, though.
* Use `-frandomize-hashtable-seed` to randomize the muxing multiplier applied to the hashcodes, which effectively prevents the exploitation of hashtables in any kind of sidechannel attack. (E.x. for probing the other keys in the hashtable based upon how long it takes to insert/write certain entries.)
* The inability to detect stack overflows creates a large vulnerable surface area for running untrusted code as it's so easy to make the C code segfault by having a function call itself recursively.
* The inability to detect and free cyclic references also creates a large vulnerable surface area for running untrusted code as it's so easy to spew a ton of cyclic objects that eat up the memory.-->

Nina is suitable for use both as a sandbox to run untrusted JavaScript and as an environment to run high security software. 

* Nina can obfuscate (not encrypt!) all JavaScript memory 



It's highly recommended that you combine Nina with C safety checks for additional security if that is one of your goals, e.x. add `-fstack-protector-strong` to the C compiler's arguments.

## Runtime encryption of ALL memory with AES-128

**Nina can encrypt all its memory (including the stack!) with AES-128 on-the-fly at only a <strike>40% (FIXME)</strike> performance hit,** holding no key information in memory ever EXCEPT when the kernel task-switches and saves all the registers to its kernel memory somewhere.

* Additionally, every different type of object and every property location therein has a different, randomly-generated order that a randomly chosen 10 out of the 15 available AES scheduling keys are applied, significantly reducing the attack surface area of Nina.
* Additionally, 11-round AES is applied instead of the usual 10, using the memory address of the data for the first round key. (Using it as the middle round key could possibility expose differential analysis if the attacker could get two memory locations known to be encrypted the same way.)
* Additionally, every memory access is preceded by the 4 unused round keys being XOR key exchange muxed against the 1 spare and continually muxed in the random order select round order until its magically XOR key exchange restored to a new different yet equivalent key state and this process is also wrapped around libcalls in a 8-before 8-after manner.
    * Basically, this makes the program *extremely likely* to be caught in an invalid and unusable state of its aes round keys when interrupted by the kernel. This is so that, if an attacker manager to find the dumped aes round key registers saved in kernel memory, it's highly likely that they are useless without *also* knowing the context of where the program was interrupted in user-space.




# IMPORTANT Optimization Options

At the heart of Nina's performance, *you* give Nina unsafe assumptions about *your* JavaScript code that technically violate the ECMAScript standard behavior but will never manifest in any differences throughout your program execution (because your code never relies upon the disabled behaviors).

It's **crucial** that you are aware of these very unsafe assumptions below so that you can toggle them to the needs of your program.

## `-O0` / `-O1` / `-O2` / `-O3` / `-Ofast` / `-Os` / `-Oz` (SAFE)

**SAFE:** Changing the optimization level should never have any effect on the observed behavior of your program. If you encounter any behavioral differences, please submit bug reports for them.

**DEFAULT:** Nina uses `-O0` by default to optimize for readability and human inspection of the output (to the extent it's reasonable to be readable): `-O0`

It's recommended you benchmark the runtime of your program at different optimization levels to see which level makes it run the fastest. For example, `-Os` might be the fastest for some programs because reducing the code size reduces the number of branches, which reduces pressure on the branch predictor. Nina's conceptual strategy for transpilation is to generate enormous quantities of always-taken and never-taken branches so that the CPU can figure out what the code is doing at runtime and skip straight to the fastest path handling all cases in the present conditions. So, the performance relies heavily on the branch predictor. If the C code exhausts the branch prediction cache (which is more likely to happen at higher optimization levels), expect significant performance degradation.

## <a name="fjs-doubles">`-fjs-doubles` / `-fno-js-doubles` (SAFE BUT DRASTIC)</a>

**SAFE BUT DRASTIC:** Disabling this option, `-fno-js-doubles` (default), requires drastic programming considerations and significant time investment, but all deviant behavior is detected at transpile time and errors out, making it *safe*. If you encounter any behavioral differences that successfully transpile without error, please submit bug reports for them.

**Default:** Disabled by default: `-fno-js-doubles`

With the default `-fno-js-doubles`, all numbers are integers without floating point decimals. Attempting to use any `Math` API (e.x. ) results in a transpile error except in the special cases noted below. Behavioral differences: 

* IMPORTANT: **intermediate expressions can temporary use floating points** as long as they are coereced to an integer before being assigned, returned, or used as a function argument.
    * *Example:* `var foo = 200 * 2/3 | 0; console.log(foo);` will successfully transpile and print `133` because `|0`&mdash;bitwise-or-with-zero&mdash;coerces its operand to a 32-bit signed int for the bitwise operation.
* IMPORTANT: Special behavior Math macros, e.x. `Math.floor(a / b)|0` in JS, change the behavior of their content to use floating points temporarily, e.x. `(int64_t)floor((double)(a) / (double)(b))` in C, and must be coerced to an integer before being assigned, returned, or used as a function argument: `Math.sqrt`, `Math.round`, `Math.cbrt`, `Math.ceil`, `Math.floor`, `Math.trunc`, `Math.random`, `Math.hypot`, `Math.log`, `Math.log10`, `Math.log2`, `Math.log1p`, `Math.fround`, `Math.exp`, `Math.exp1m`, `isNaN`, `Number.isNaN`, `isFinite`, `Number.isFinite`, and `Number.isSafeInteger`
    * *Example:* `var foo = Math.ceil(200 * 2/3) | 0; console.log(foo);` will successfully transpile and print `134`.
    * *Example:* `Math.hypot.apply(null, [3, 4])` will ERROR and fail to transpile because `Math.hypot` is only available as a special-behavior macro and cannot be used as a normal JavaScript function value.
* `Math.imul` and `Math.clz32` are available as normal functions and not macros.
* `Math.max`, `Math.min`, `Math.abs`, `Math.sign`, and `Math.pow` are available as both special behavior macros and normal functions. In their latter normal function form, they only operate on integers, ultimately exhibiting the same behavior as normal compliant JavaScript EXCEPT in the case of `NaN`, which becomes 0. For example, `-fno-js-doubles` causes `Math.abs("not a number!")` to incorrectly yield `0` instead of the expected `NaN`.
* All other `Math.*` operations are unavailable and will result in a transpile error stating that you must enable doubles with `-fdoubles`
* `parseInt`, `parseFloat`, `Number.parseInt`, and `Number.parseFloat` are special-behavior macros whose return values must be coerced to integers before being assigned or used as function arguments.
    * *Example:* `var foo = Math.ceil(parseFloat("1.234"))|0;` is valid, transpiles successfully, and gives the expected result of `2`.
    * *Example:* `var flt = parseFloat("1.234"); var foo = Math.ceil(flt)|0;` errors out and won't transpile because the intermediary floating point from the `parseFloat` macro cannot be held in a variable.
* The special-behavior `isNaN`, `Number.isNaN`, `isFinite`, `Number.isFinite`, and `Number.isSafeInteger` macros additionally accept explicitly-coerced string arguments in the form `isNaN("" + yourVariable)` to test if the string is a valid number or too big to be held in a double precision floating point.
* `JSON.parse` coerces all numbers to integers as if `x | 0` were done on them

For example, take the following JavaScript code that parses a floating point string to a rounded-down integer:

```js
// This JS code ERRORS out when attempting to transpile with `-fno-js-doubles` (default)
function parseFloatRoundDownOrDefault(str, defaultValue) {
    var asFlt = parseFloat(str);
    if (isNaN(asFlt) return defaultValue;
    return Math.floor( asFlt );
}
```

To fix this code so that Nina can transpile it, all use of floating points must be temporary:

```js
// This JS code transpiles SUCCESSFULLY with `-fno-js-doubles` (default)
function parseFloatRoundDownOrDefault(str, defaultValue) {
    if (isNaN("" + str)) return defaultValue;
    return Math.floor( parseFloat(str) ) | 0;
}
```

Or, alternately, if you were only working with positive integers, you could just as well parse the string as an integer:

```js
// This JS code transpiles SUCCESSFULLY with `-fno-js-doubles` (default)
function parseFloatRoundDownOrDefault(str, defaultValue) {
    if (isNaN("" + str)) return defaultValue;
    return parseInt(str) | 0; // Notice: no Math.floor
}
```

One of the many obscure advantages of disabling doubles is that it enables Nina to globally assume that `x === x` will always be true regardless of x's value, which helps Nina generate shorter, faster C code. In JavaScript, there's only one case where `x !== x` and that's `NaN`.

*What if I just need to store floating points in one small, tiny area of my code?* In that case, I reccomend storing the floating points as strings and parsing those strings as-needed in order to keep everything as temporary floating point expressions so that doubles don't get stored anywhere. Enabling `-fjs-doubles` will slow the performance of your entire program, so try to avoid it if the time spent parseInt/toString on temporary float expressions is unnoticeable.

## `-flibuv-event-loop` (SAFE BUT DIFFICULT TO INTEGRATE)

**SAFE BUT DIFFICULT TO INTEGRATE:** Enabling libuv should never have any effect on the observed behavior of your program. If you encounter any behavioral differences, please submit bug reports for them.

**DEFAULT:** Nina disables this by default at all optimization levels: `-fno-libuv-event-loop`


## `-fjs-gc-thread` / `-fno-js-gc-thread` (SAFE BUT MASSIVE OVERHEAD)

**SAFE BUT MASSIVE OVERHEAD**: Enabling this option, `-fjs-gc-thread` (not default), imposes an additional 1mb of overhead per thread for the memory allocation arenas.

**DEFAULT:** always disabled at all optimization levels: `-fno-js-gc-thread`

UNLOCK THE SUPER-ULTRA-RIDICU-MAX&#8482; PERFORMANCE BEAST MODE!!!!: low-pause-time fully-concurrent multithreaded garbage collection that scales smoothly from megabyte-size working memory to terabyte-size working memory.

I don't know jackshit about what everyone else is doing in their garbage collectors and my adhd poses a real problem 

The biggest caveat to having a GC thread reading data as it is written is that all  stores of pointers and `NinaValue_t`s must be atomic to avoid tearing. At every one of these points, memory must be stored via `atomic_store` with `memory_order_relaxed`. This isn't a problem on x86-64 as its memory model guarantees this by default (and Nina silently no-ops the atomic loads/stores to help GCC optimize) but it can possibly pose performance pitfalls on other architectures. Please post bug reports of CPUs that experience worse performance with `-fjs-gc-thread` enabled to help me keep track of this.


# Other Optimization Options

You are much less likely to encounter these options in your program, so it might be best to just use the simple `-O` optimization level and let Nina automatically decide the settings for these flags.

## `-fundefined-not-in-object` / `-fno-undefined-not-in-object` (UNSAFE)

**UNSAFE**: This will significantly impact the running of your JavaScript program and cause behavior that deviates far away from the ECMAScript standard.

**DEFAULT:** always disabled at all optimization levels: `-fno-undefined-not-in-object`




## `-fjs-null-equals-undefined` / `-fno-js-null-equals-undefined` (UNSAFE)

**UNSAFE**: This will significantly impact the running of your JavaScript program and cause behavior that deviates far away from the ECMAScript standard.

**DEFAULT:** always disabled at all optimization levels: `-fno-js-null-equals-undefined`

## `-fstack-temporaries` / `-fno-stack-temporaries` (SAFE)

**SAFE:** Disabling option, `-fno-stack-temporaries`, has no impact whatsoever on the observed behavior of your program. If you encounter any behavioral differences, please submit bug reports for them.

**Default**: enabled, `-fstack-temporaries`, at all optimization levels except `-Oz`. At `-Oz`, this is disabled by default ONLY IF exceptions are also disabled&mdash;`-fno-exceptions`&mdash;because stack temporaries serve as the mechanism for stack unwinding (and memory ``free`ing) during exceptions. So, implementing exceptions without stack temporaries requires wrapping EVERY function in a try/catch/throw-propagate to free its variables' memory during exceptions.

All memory allocations 


```js
function set0(arr, value) {
    arr[0] = value;
    return arr;
}
function generateListOfArrays(n) {
    for (var i=0; i < n; i++) {
      
    }
}
```


Here is the generated C code with `-fstack-temporaries -fno-fastpath`


## `--fastpath-limit=n` / `-ffastpath` / `-fno-fastpath` (SAFE)

**SAFE:** Disabling option, `-fno-stack-temporaries`, has no impact whatsoever on the observed behavior of your program. If you encounter any behavioral differences, please submit bug reports for them.

**Default:** `--fastpath-limit=1` at `-Os`, `-O0`, and `-O1`; then, `--fastpath-limit=2` at `-O2`; then, `--fastpath-limit=3` at `-O3`; then, `--fastpath-limit=4` at `-O4` and `-Ofast`; finally, `--fastpath-limit=0` at `-Oz`

**N.B.:** `-fno-fastpath` is exactly equivalent to `--fastpath-limit=0`; and `-ffastpath` is exactly equivalent to `--fastpath-limit=1`

## `-funlimited-precision` / `-fno-unlimited-precision` (ALMOST SAFE)

**ALMOST SAFE:** Disabling option, `-fno-unlimited-precision`, should have no impact on the observed behavior of any normally written code used in real programs. However, it's possible to create pathological test cases that exploit deviant behavior under `-funlimited-precision`. If you encounter any *unexpected* behavioral differences, please submit bug reports for them.

**Default:** always enabled: `-funlimited-precision`

If you enable `-fdoubles` (not default) and `-funlimited-precision` (default), then Nina assumes no weird floating point rounding errors will ever happen, enabling it to optimize this JavaScript to the C code below. 

```js
// Source JavaScript code for this example
function addAPlusBMinusA(a, b) {
    return a + b - a;
}
console.log(addAPlusBMinusA(0.1, 0.2) === 0.2); // logs `false` due to precision errors
console.log(addAPlusBMinusA(0.1, 0.2) - 0.2); // logs `2.7755575615628914e-17`, not zero 
```

Notice `a + b - a`. With the default `-funlimited-precision`, addition is assumed to be associative, which causes errant incorrect behavior in this edge case:

```c
// Generated C with `-funlimited-precision -fdoubles` (Note: `-funlimited-precision` is default)
// This program IS ERRANT and exhibits wrong behavior
NinaValue_t addAPlusBMinusA(void* ninaCTX, const void* aType, uint64_t aValue, const void* bType, uint64_t bValue) {
    NinaValue_t a = {aType, aValue};
    NinaValue_t b = {bType, bValue};
    if ((ninaTypeMask(a.type) & (NINATYPEMASK_INT|NINATYPEMASK_DOUBLE)) != 0 && (ninaTypeMask(b.type) & (NINATYPEMASK_INT|NINATYPEMASK_DOUBLE)) != 0) {
        // (Note: This fastpath speeds up the case where a is an int or a double and b is an int or a double)
        return b;
    } else {
        // (Note: This is the fallthrough slow path. Nina is optimistic that this path won't be taken)
        ninaGcMarkStackMACRO(_gcBookmarkVar);
        
        NinaValue_t _tmpA = ((NinaRtti_t *) a.type)->opAdd(/*options:*/0, a.type, a.value, b.type, b.value);
        NinaValue_t _tmpB = {NINATYPE_DOUBLE, ninaToDouble(/*options:*/0, _tmpA.type, _tmpA.value) - ninaToDouble(/*options:*/0, b.type, b.value));
        ninaTryToCastToIntMACRO(_tmpB);
         
        jsGcFreeStackMACROnoPreserve(_gcBookmarkVar);
        return _tmpB;
    }
}
int main(const char** argv, int argc) {
    jsSetupEnvironment(argv, argc);
    ninaGcMarkStackMACRO(_gcBookmarkVar);
    
    NinaValue_t tmpA = addAPlusBMinusA(/*context:*/NULL, NINATYPE_DOUBLE, /*double 0.1:*/UINT64_C(0x3fb999999999999a), NINATYPE_DOUBLE, /*double 0.2:*/UINT64_C(0x3fc999999999999a));
    printf("%s\n", tmpA == 0.2); // wrongly logs `true`
    NinaValue_t tmpB = addAPlusBMinusA(/*context:*/NULL, NINATYPE_DOUBLE, /*double 0.1:*/UINT64_C(0x3fb999999999999a), NINATYPE_DOUBLE, /*double 0.2:*/UINT64_C(0x3fc999999999999a));
    printf("%f\n", ninaToDouble(/*options:*/0, tmpB.type, tmpB.value) - 0.2); // wrongly logs 0
    
    jsGcFreeStackMACROnoPreserve(_gcBookmarkVar);
    return 0;
}
```

Notice how Nina optimized `return a + b - a;` into `return b;` because `-funlimited-precision` gives it permission to assume that floating point errors never happen, so addition and subtraction are associative.

Yes!, having to set up the stack with `ninaGcMarkStackMACRO` and `ninaGcFreeStackMACRO` is quite ugly, but it's necessary to correctly handle if `addAPlusBMinusA` is passed a string. For example, Nina correctly transpiles the code so that `addAPlusBMinusA("1", "2")` correctly yields `11`. Indeed, JavaScript is very weird.

Compare this to `-fnounlimited-precision` (not default) below, where Nina is not allowed to make such unsafe optimizations, so the transpiled code exhibits correct behavior.

```c
// Generated C with `-funlimited-precision -fdoubles --fastpath-limit=2`
// This program IS GOOD and exhibits the correct behavior
NinaValue_t addAPlusBMinusA(void* ninaCTX, const void* aType, uint64_t aValue, const void* bType, uint64_t bValue) {
    NinaValue_t a = {aType, aValue};
    NinaValue_t b = {bType, bValue};
    if ((ninaTypeMask(a.type) & ninaTypeMask(b.type) & NINATYPEMASK_INT) != 0) {
        // (Note: This fastpath speeds up the case where a is an int and b is an int)
        return (NinaValue_t){NINATYPE_INT, a.value + b.value - a.value};
    } else if ((ninaTypeMask(b.type) & ninaTypeMask(a.type) & NINATYPEMASK_DOUBLE) != 0) {
        // (Note: This fastpath speeds up the case where a is a double and b is a double)
        double _tmpA = (*(double *)&a.value) + (*(double *)&b.value) - (*(double *)&a.value);
        return (NinaValue_t){NINATYPE_DOUBLE, (*(uint64_t *)&_tmpA)};
    } else {
        // (Note: This is the fallthrough slow path. Nina is optimistic that this path won't be taken)
        ninaGcMarkStackMACRO(_gcBookmarkVar);
        
        NinaValue_t _tmpB = ((NinaRtti_t *) a.type)->opAdd(/*options:*/0, a.type, a.value, b.type, b.value);
        NinaValue_t _tmpC = {NINATYPE_DOUBLE, ninaToDouble(/*options:*/0, _tmpB.type, _tmpB.value) - ninaToDouble(/*options:*/0, b.type, b.value));
        ninaTryToCastToIntMACRO(_tmpC);
         
        jsGcFreeStackMACROnoPreserve(_gcBookmarkVar);
        return _tmpC;
    }
}
int main(const char** argv, int argc) {
    jsSetupEnvironment(argv, argc);
    ninaGcMarkStackMACRO(_gcBookmarkVar);
    
    NinaValue_t tmpA = addAPlusBMinusA(/*context:*/NULL, NINATYPE_DOUBLE, /*double 0.1:*/UINT64_C(0x3fb999999999999a), NINATYPE_DOUBLE, /*double 0.2:*/UINT64_C(0x3fc999999999999a));
    printf("%s\n", tmpA == 0.2); // CORRECTLY logs `false` due to precision errors
    NinaValue_t tmpB = addAPlusBMinusA(/*context:*/NULL, NINATYPE_DOUBLE, /*double 0.1:*/UINT64_C(0x3fb999999999999a), NINATYPE_DOUBLE, /*double 0.2:*/UINT64_C(0x3fc999999999999a));
    printf("%f\n", ninaToDouble(/*options:*/0, tmpB.type, tmpB.value) - 0.2); // CORRECTLY logs `2.7755575615628914e-17`, not zero 
    
    jsGcFreeStackMACROnoPreserve(_gcBookmarkVar);
    return 0;
}
```

Observe how, in the correct, functional program above, Nina creates three different paths for `addAPlusBMinusA`&mdash;one path to cover int and int, one path to cover double and double, and one slow path to cover the rest of the cases.


## `-frtti` / `-fno-rtti` (SAFE BUT DRASTIC)

**SAFE BUT DRASTIC:** Disabling this option, `-fno-rtti`, requires drastic programming considerations and significant time investment, but all deviant behavior is detected at transpile time and errors out, making it *safe*. If you encounter any behavioral differences that successfully transpile without error, please submit bug reports for them.

**Default:** Always enabled by default: `-frtti`

Disabling with `-fno-rtti`&mdash;run time type information&mdash;disables polymorphism (being able to freely hold any value in any variable), preventing any non-typed JavaScript code from transpiling and erroring out.

This DOES NOT enable any additional optimizations whatsoever and will not make your code run faster.

This option simply turns the existing untyped warnings into untyped errors AND disables usage of the asterisk any-type.

This flag might be useful if you want to go all-the-way with optimizing your JavaScript to the same speed as C/C++. When given full explicit type information and no polymorphism, Nina is able to bypass all JavaScript overhead and produce neat, easy-to-read, C code that runs almost as fast as if your program were written in C.

However, usage of this flag is generally discouraged as it provides no performance benefits&mdash;using `-fno-rtti` simply turns warnings into errors and nothing more. And, there is nothing wrong with using the asterisk any-type to make your code neater and more expressive&mdash;the asterisk any-type only incurs a slight performance hit on the variables that use it and a slight memory overhead (to tag rtti data) on all areas of the code that may interact with the method using the asterisk any-type.

# <a name="c-apis">C APIs</a>

Prerequisite: read [Event loop and integrating JS](#event-loop-and-integrating-js) first so for basic knowledge of how the setup in C works.

## <a name="event-loop-c-apis">Event loop C APIs</a>

### `uint64_t ninaEventLoop(void);`

**Usage:** Call `ninaEventLoop()` then 

IMPORTANT: `ninaEventLoop(void)` MUST be called at least once before you call *any* JavaScript function from C/C++! If you are 

**Returns:** `ninaEventLoop()` returns the time in nanoseconds (relative to an unspecified point in the past) as a `uint64_t` that the next event loop is currently scheduled to run at. This value may change and decrease if your C code adds callbacks to the event loop or I/O operations complete early, so consider this return value to be a *prediction* of when the next event loop will run so that you can design your C code to hold-off on its work when the time comes for the next event loop to run. 

IMPORTANT: The return value from `ninaEventLoop()` will be `UINT64_MAX` if it is unknown when the next event loop will run, so it's *highly recommended* you clamp the return value of `ninaEventLoop` to a maximum value such as 50ms in the future.

Example of clamping the return value of `ninaEventLoop()`:


This performs three very important utilities in this order:

1. FIRST, `ninaEventLoop()` checks if this is the very first call to it. If so, it runs Nina's setup code and runs the JavaScript global scope. (In the first call, it also skips steps #2 and #3). If the JavaScript has a top-level `await`, then this first call to `ninaEventLoop` will block until all top-level-awaits resolve and the global scope finishes.
2. SECOND, `ninaEventLoop()` checks the status of all pending I/O operations and adds any completed I/O operations onto the end of its queue this tick.
3. THIRD, `ninaEventLoop()` executes all queued callbacks scheduled for this tick.

For more details and the specific order that things are executed, see [the NodeJS docs on the event loop](https://nodejs.org/en/guides/event-loop-timers-and-nexttick#phases-overview). (In particular, I highly recommend understanding the [`setImmediate` vs ``process.nextTick`](https://nodejs.org/en/guides/event-loop-timers-and-nexttick#processnexttick-vs-setimmediate) section and how they are both misnomers.)


Use `ninaNextScheduledEventNS()` and `ninaIsIOScheduled()` for more fine-grained monitoring of the event loop but be careful: `ninaNextScheduledEventNS()` will return `INT64_MAX` if there's nothing currently scheduled.

# Nina's Memory Management

To start off with, Nina has three places where data can reside:

1. The main memory heap
2. Async context variable data
3. A linked-list stack that grows downwards

Nina attempts to intelligently choose the best place to allocate memory to minimize copying like so:

* An object *likely* to be persistent and stay around for a long time will be proactively allocated upon the main memory heap.
* An object with properties added in a loop does a precheck for the number of loop iterations if it can't be statically analyzed and, if its anticipated to grow large enough, is allocated directly upon the heap.
    * Additionally, this serves as a safety check: if the allocated property volume would overflow the stack and cause runaway memory usage, then all of it becomes slow reference-counted heap usage that frees-as-it-goes.
* An object *likely* to be returned will be allocated within the stack of the caller to perform a zero-copy maneuver.
* Any context variables that span a Promise or an `await` are automatically promoted to be allocated in the async context variable data.
* If Nina tracks the path of a callback function to an async-like area of the code that will call it once or twice sometime later, then the context variables captured by the callback are upgraded to the async context variable data.
    * A great example is the context held by generator `function*`s, which is expected to be ephemeral in nature if not used synchronously

The Async context variable data is separated as cold-storage of objects expected to have a temporary lifespan:

* The *primary* purpose of separating Async context variable data is to (significantly) reduce main memory heap fragmentation. It's expected that the Async context variable data will take performance hits from its own fragmentation but that this fragmentation will be ephemeral as its predicted that the objects held in Async context variable data will only stay around until the promise or callback completes before being freed.
* Small Async context variable data is fitted into slots of its data size in a linked-list fast allocator.
* Larger Async context variable data falls straight to malloc/free, even in the presence of the garbage collector, taking this tiny performance hit to minimize overhead.
* Nina tracks usage of the async context variable data and flushes the previous cache line (64 bytes lower) in each slotted objet size chunk allocation region out to main memory via CLFLUSHOPT to keep the cache tight and clean for the rest of the program.
* The Async context variable data is restricted primarily to local context variables that won't be used to hold variables likely to be assigned anywhere, thus significantly reducing the problem of address rewrite proxies junking up the data space.

One addition intelligent transformation Nina applies is stack-substitution for callees that allocates their return variable within the stack of the caller:

* If a called function is known to only use the stack for its return value AND the return value is a primitive number, Nina preallocates the slot of the return value in the destination object and substitutes the stack with this address so that the value is zero-copy placed within its final destination.
* If a called function is known to allocate an object, then nina may substitute the stack with the garbage collector's Eden region so that the return value is zero-copy allocated into place upon the heap. This gives an extra performance boost to nested returned objects, as the return from the callee must collect it contiguously in memory before being returned to the caller anyway.
    * If this optimization is used in your program, then Nina auto-generates additional logic put into the garbage collector for there to be a linked-list stack pointer from the bottom of the Eden region so that it can serve all the same functionality as the normal stack.
* This optimization is extremely limited for async context variable data as it requires knowing the type of the data that will be there and a guarantee there will be no other usage of the substituted stack than the return value, so it often falls back to copying in this case.
 
Persistent memory cannot retain pointers to the ephemeral objects in the heaps, which is why all objects have a CoHR/Copy-on-Heap-reference tag. If you attempt to put a stack object (CoHR > 0) into a heap object (CoHR=0) OR you attempt to put a stack object into caller's stack object (CoHR<sub>1</sub> &lt; CoHR<sub>2</sub>), then:

1. The stack object is moved to the heap
2. If we have the source of the stack object, its updated to reflect the new location in the heap
3. If the stack object's reference count is greater than 0, then its still referenced somewhere in the stack, so we replace the stack object's location in the stack with an address rewrie proxy object, which rewrites references to the stack object to point to its new location in the heap, decrement the reference count with each rewrite until it can be freed
   * Notice: objects on the stack don't need to be freed, so this last decrement-and-free part is only used by Garbage Collector for its allocation regions to reclaim fragmentation from immovable object proxies.
   
Also note all stack objects are weak and don't update reference count when CoHR is non-zero
   
Notice specially in the case of stack object to heap to be put into caller stack object&mdash;CoHR<sub>1</sub> &lt; CoHR<sub>2</sub>&mdash;, a stack object cannot reference a 0-reference count object upon the heap or it will never be freed (which becomes the case as heap objects can only *weakly* referenced by stack objects without incrementing or decrementing the reference count of the heap object.) So, the container stack object in the parent must also be moved to the heap.


# \[Internals:\] The NinaGC

<center>
![NinaGC memory regions diagram](resources/ninagc-diagram-regions.png)
</center>

First, how is NinaGC slapped on top of the generated code or absent at the flip of a switch? At the most basic level, NinaGC inserts itself as an intermediary layer inbetween Nina's `malloc` requests for memory and the actual stdlib calls to `malloc` (for small objects only). Even when the GC is active, Nina still uses its intelligent stack temporaries system to significantly reduce pressure on NinaGC. 

In order for the GC to work, a ton (40 bytes if 64-bit pointers or 28 if 32-bit pointers) of metadata must be added to every object:

```c
typedef struct __ninaGCObject {
	struct __ninaGCObject** lastModifiedObjectPMO;// pointer to the last modified object's lastModifiedObjectPMO field
	struct __ninaGCObject** nextModifiedObjectNMO; // pointer to the next modified object's nextModifiedObjectNMO field
	uint64_t generation;
	uint32_t refCount : 31;
	uint32_t isInline : 1;
	uint32_t length;
	struct __ninaGCObject* location;
} __ninaGCObject_t;
```



Nina's GC is a rather simple *generational* copying garbage collector, which manages the heap into three buffers:

1. The Eden region (primary)
2. The Survivor region (secondary) accumulates 
3. The main memory heap buffer

Below is a simplified diagram of the GC:



## NinaGC's Lock-free Modified Object DL list

The modified objects DL&mdash;doubly-linked&mdash;list is a FIFO-like queue embeded into every allocated chunk of memory that keeps track of which memory has changed since the last GC cycle so that pointers can be updated from the Eden region to the Survivor region to the main heap so that it's safe to free the temporary.

 
 The only requirement for this to be 100% safe in practice is that memory stores from speculative execution must never be temporarily visible to other threads. This could result the case of a speculatively-executed JS object access resulting in the temporary removal of the accessed object from the modified object dl list while the GC thread is traversing it and the subsequent re-insertion of that object undoing the speculative execution, causing the gc to skip checking that modified object and creating a memory leak whereby, if that object is never accessed again, then it will retain a strong hold on the proxy object in the Eden/survivor space. This could lead to eventual exhaustion of the Eden or survivor space and program abortion due to unfreed pointer proxies. Thankfully, [this SO post](https://stackoverflow.com/questions/57937532/can-a-load-or-store-be-reordered-before-a-conditional) and [this other SO post](https://stackoverflow.com/questions/64141366/can-a-speculatively-executed-cpu-branch-contain-opcodes-that-access-ram) assert that this will never happen :)

<!--To guarantee full memory barriers and prevent myself from fucking up the atomics, every iteration of the modified objects DouLL is wrapped in a thread-local mutex private to the GC thread.-->

# Contributions

Of course contributions are welcome!, but what specifically can you do to help?

### I need YOUR HELP to integrate Rust

If you are an experienced Rustacean, open an issue, let's exchange contact information, and let's work together to integrate the Rust as both a target and a source for Nina.

<!--### I need YOUR HELP to fix MSVC performance

If you know assembly across several platforms really well and have an hour or two of time, you can help speed up Nina's try/catch error faculties *signifigantly* by writing hand-optimized-assembly versions of `ninaWrapTryCatchFinally` and `ninaThrowError` specific to all the architectures and abis you know.

See [this godbolt](j) for the relevant code and hack at it! Post your optimized version as an issue and I'll see it and integrate it into Nina. Notes:

IMPORTANT: you must write your code in GNU inline assembly (inside a `__attribute__((naked))` function I guess?) with variants for ALL the dialects of the assembler on your platform! (see [Extended-Asm.html](https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html#Multiple-assembler-dialects-in-asm-templates)). Also, it would help if you could provide all your assembly versions as one giant lump of C code `#ifdef`-ed to each architecture its for. I'm trying to learn assembly but I'm no good at it yet, which is why I need your help.

Nina's `try`/`catch` performance problems are *egregious to the highest degree conceivable* in MSVC because Nina currently falls back to `setjmp`, which, in MSVC, saves 10 general registers, 2 status registers, 8 sse registers, and (I suspect) makes a kernel call involving signal masking for interrupt handler safety. See [the horror for yourself](https://github.com/icestudent/vc-19-changes/blob/master/setjmp.h#L56). If you want Nina's performance to be less bad in MSVC, then design an inline assembly version of `ninaWrapTryCatchFinally` for MSVC (based on [that godbolt](j)) and post your code as an issue.-->

# <a name="license">License</a>

The Nina project is copyrighted solely by myself, Jack G., and licensed under the most glorious and holy of all licenses ever conceived. That's right!: the RMS-blessed *GPL-3.0-only or GPL-3.0-or-later*. (Note its incorrect to abbreviate this to *GPL-3.0-or-later*. See [this blessed manuscript from the man Himself](https://www.gnu.org/licenses/identify-licenses-clearly.html).)

Any files generated by Nina are your own work, are subject to your own exclusive copyright, and are removed from any ramifications of the licensing of Nina.

Libnina &mdash; the transpiler itself &mdash; is GPL-licensed, is copyrighted by myself, and cannot be incorporated into any non-GPL-licensed project. Specifically, libnina's *GPL-3.0-only or GPL-3.0-or-later* license excludes the GPLv2, preventing any including project from using GPLv2.

I'm not evil; I'm just a young-and-dumb 21-year-old man who probably drinks too much alcohol, wayyy too much coffee, and maybe a tad too much of the sweet nectar of idealism.
So, I have additionally provided a dump of all strings throughout the Nina project in this single file: [`code-strings.txt`](./resources/code-strings.txt), licensed under the permissive MIT.
In the event of any sort of legal conflict, you can claim the pieces of source code constituting your files generated by Nina came from the permissively licensed `code-strings.txt` and not from the GPL-licensed Nina source code, thus escaping any theoretical legal ramifications.
`code-strings.txt` additionally includes all code snippets from this README so that you can freely use them in any work, which means that all code snippets in this README are MIT-licensed, permitting free usage of them in any project.

Thank you!, Nina, for putting up with the endless quirky shenanigans central to my personality. I love you in the sense of a best friend!, I couldn't have made this project without your support!, and I can't imagine my life without such a loyal, amazing friend!

# When 1.0 release?
Great Question!

## Paid Tech Support for Nina

**Nina will always be 100% free, libre GPL-licensed software!**, and you can pay a subscription fee to have the lead developers on same-business-day speed-dial to educate and help your team with Nina to boost their productivity and save you lots of money.
